{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "NumPy: 1.16.4\n",
      "Pandas: 0.25.3\n",
      "Scikit-learn: 0.23.2\n",
      "SpaCy: 2.3.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy:\", np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"Scikit-learn:\", sklearn.__version__)\n",
    "\n",
    "import spacy\n",
    "print(\"SpaCy:\", spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the SMS Spam Collections dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  x\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t',names= ['y', 'x'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y                       x\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1cd5e72100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['x'].apply(len).plot(bins=50, kind='hist') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and POS-tag the input texts with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "df['tokens'] = df['x'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>(Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[VERB, ADP, ADJ, NOUN, PUNCT, ADJ, PUNCT, ADJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>(Ok, lar, ..., Joking, wif, u, oni, ...)</td>\n",
       "      <td>[INTJ, NOUN, PUNCT, NOUN, CCONJ, PROPN, PROPN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>(Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[ADJ, NOUN, ADP, NUM, DET, NOUN, NOUN, PART, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>(U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>(Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  x  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  (Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           (Ok, lar, ..., Joking, wif, u, oni, ...)   \n",
       "2  (Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  (U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  (Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [VERB, ADP, ADJ, NOUN, PUNCT, ADJ, PUNCT, ADJ,...  \n",
       "1  [INTJ, NOUN, PUNCT, NOUN, CCONJ, PROPN, PROPN,...  \n",
       "2  [ADJ, NOUN, ADP, NUM, DET, NOUN, NOUN, PART, V...  \n",
       "3  [PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, PR...  \n",
       "4  [INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS-tag\n",
    "df['pos'] = df['tokens'].apply(lambda x: [i.pos_ for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>(Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[VERB, ADP, ADJ, NOUN, PUNCT, ADJ, PUNCT, ADJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>(Ok, lar, ..., Joking, wif, u, oni, ...)</td>\n",
       "      <td>[INTJ, NOUN, PUNCT, NOUN, CCONJ, PROPN, PROPN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>(Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[ADJ, NOUN, ADP, NUM, DET, NOUN, NOUN, PART, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>(U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>(Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  x  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  (Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           (Ok, lar, ..., Joking, wif, u, oni, ...)   \n",
       "2  (Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  (U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  (Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [VERB, ADP, ADJ, NOUN, PUNCT, ADJ, PUNCT, ADJ,...  \n",
       "1  [INTJ, NOUN, PUNCT, NOUN, CCONJ, PROPN, PROPN,...  \n",
       "2  [ADJ, NOUN, ADP, NUM, DET, NOUN, NOUN, PART, V...  \n",
       "3  [PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, PR...  \n",
       "4  [INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do POS-tag based and list-based stop-word filtering using ​ spaCy​ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop word filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_worlds(tokens):\n",
    "    filtered_tokens = []\n",
    "    for t in tokens:\n",
    "        if not t.is_stop:\n",
    "            filtered_tokens.append(t)\n",
    "    return ' '.join([str(x) for x in filtered_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jurong point , crazy .. Available bugis n grea...\n",
       "1                         Ok lar ... Joking wif u oni ...\n",
       "2       Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3                             U dun early hor ... U c ...\n",
       "4                              Nah think goes usf , lives\n",
       "                              ...                        \n",
       "5567    2nd time tried 2 contact u. U won £ 750 Pound ...\n",
       "5568                        ü b going esplanade fr home ?\n",
       "5569                    Pity , * mood . ... suggestions ?\n",
       "5570    guy bitching acted like interested buying week...\n",
       "5571                                          Rofl . true\n",
       "Name: tokens, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_filtered = df['tokens'].apply(lambda x: filter_stop_worlds(x))\n",
    "stop_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train 3 classical ML-based classifiers on TF-IDF BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(stop_filtered)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 8523)\n",
      "(4457,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820627802690582"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8887892376681614"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train.toarray(), y_train)\n",
    "gnb.score(X_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775784753363229"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords_and_get_lemma(tokens):\n",
    "    filtered_tokens = []\n",
    "    for t in tokens:\n",
    "        if not t.is_stop:\n",
    "            filtered_tokens.append(t.lemma)\n",
    "    return ' '.join([str(x) for x in filtered_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14096818269429646414 15479733260938818482 2593208677638477497 16792598155547231470 8848021949395737739 4887332976578131782 3557720637082594454 13210364986222294696 8881679497796027013 1703489418272052182 6804705863737483857 1720370409040345145 9503240487077079950 10875615029400813363 3040539950272399101 2013399242189103424 15198862986666964157 8445541832527975875 10875615029400813363'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_stopwords_and_get_lemma(df['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer=filter_stopwords_and_get_lemma)\n",
    "X = vectorizer.fit_transform(df['tokens'])\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663677130044843"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7614349775784753"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train.toarray(), y_train)\n",
    "gnb.score(X_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013452914798207"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                   Results\n",
      "                     With text                With lemma\n",
      "SVM               0.9820627802690582      0.8663677130044843\n",
      "Naive Bayes       0.8887892376681614      0.7614349775784753\n",
      "Random Forest     0.9775784753363229      0.9013452914798207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"\n",
    "                                   Results\n",
    "                     With text                With lemma\n",
    "SVM               0.9820627802690582      0.8663677130044843\n",
    "Naive Bayes       0.8887892376681614      0.7614349775784753\n",
    "Random Forest     0.9775784753363229      0.9013452914798207\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
